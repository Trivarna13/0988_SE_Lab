{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui9cLjMdn17_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL61Pc3_S06E"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/Knee-project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl1j2aXXv_Co"
      },
      "source": [
        "# Dataset Link:\n",
        "https://data.mendeley.com/datasets/t9ndx37v5h/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nubcDsUpvn1"
      },
      "source": [
        "## for more project and Data sceince materials folow our blog link below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lvaE7kipvn2"
      },
      "source": [
        "# http://buffml.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfJdpAe7pvn2"
      },
      "source": [
        "# Youtube channel:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvaRsGREpvn2"
      },
      "source": [
        "# https://www.youtube.com/c/artificialintelligencehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcJvFmOTznEi"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTL9JAB_zn0k"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqs8xkUUT7ex"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k89Phl5nTfYU"
      },
      "outputs": [],
      "source": [
        "import cv2,os\n",
        "data_path='/content/drive/MyDrive/Knee-project/Knee-Dataset/'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "label_dict=dict(zip(categories,labels)) #empty dictionary\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BScfeIRlTtlL"
      },
      "outputs": [],
      "source": [
        "img_size=256\n",
        "data=[]\n",
        "label=[]\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "        try:\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            resized=cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the image  into 256 x 256, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            label.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYQHryCXVQa9"
      },
      "source": [
        "# Recale and assign  catagorical labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRj6dU9zTxNw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "label=np.array(label)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "new_label = to_categorical(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Ww7WuoeRAo"
      },
      "outputs": [],
      "source": [
        "new_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at-tkV9EUH8v"
      },
      "source": [
        "#CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5yQijqzVHJN"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1JcfG4MdVZ2"
      },
      "outputs": [],
      "source": [
        "data.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgsZogOtUPm2"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(128,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The first CNN layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The second convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Conv2D(32,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The thrid convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Flatten())\n",
        "#Flatten layer to stack the output convolutions from 3rd convolution layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "#Dense layer of 128 neurons\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "#Dense layer of 64 neurons\n",
        "\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "#The Final layer with two outputs for two categories\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfCMzZEpcyAM"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzs7FPsncqKT"
      },
      "source": [
        "# Splitting data into traning and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oHT4H09UT8-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(data,new_label,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3BCXcrumxpv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(20):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.squeeze(x_test[i]))\n",
        "    plt.xlabel(categories[np.argmax(y_test[i])])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmpEGWUMUUnh"
      },
      "outputs": [],
      "source": [
        "history=model.fit(x_train,y_train,epochs=100,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWIlgOnjzdhT"
      },
      "outputs": [],
      "source": [
        "# model.save('model.h5')\n",
        "model.save('/content/drive/MyDrive/Knee-project/model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTE4J3IGUWlt"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1TU9-z2UZlj"
      },
      "outputs": [],
      "source": [
        "# plot the training loss and accuracy\n",
        "N = 100 #number of epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"center right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "plt.savefig(\"/content/drive/MyDrive/CNN_Model.png\")"
      ],
      "metadata": {
        "id": "s21Ybtc_qBZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBKLBWTroYTu"
      },
      "outputs": [],
      "source": [
        "vaL_loss, val_accuracy= model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"test loss:\", vaL_loss,'%')\n",
        "print(\"test accuracy:\", val_accuracy,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO_qh8EZl8qZ"
      },
      "outputs": [],
      "source": [
        "X = 32\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "img_single = x_test[X]\n",
        "img_single = cv2.resize(img_single, (img_size, img_size))\n",
        "img_single = (np.expand_dims(img_single, 0))\n",
        "img_single = img_single.reshape(img_single.shape[0],256,256,1)\n",
        "\n",
        "predictions_single = model.predict(img_single)\n",
        "print('A.I predicts:',categories[np.argmax(predictions_single)])\n",
        "print(\"Correct prediction for label\",np.argmax(y_test[X]),'is',categories[np.argmax(y_test[X])])\n",
        "plt.imshow(np.squeeze(img_single))\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO55PPeenshy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "predictions = model.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "cm  = confusion_matrix(test_labels, predictions)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(5), ['Normal','Doubtful','Mid','Moderate','Severe'], fontsize=16)\n",
        "plt.yticks(range(5), ['Normal','Doubtful','Mid','Moderate','Severe'], fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzow6xG4pvn6"
      },
      "source": [
        "# My GitHub Profile Link:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbp-AK7EpXSJ"
      },
      "source": [
        "# https://github.com/noumannahmad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqe4ST4Kpvn6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}